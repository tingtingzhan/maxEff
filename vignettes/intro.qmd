---
title: "Additional Predictor with Maximum Effect Size"
author: Tingting Zhan
date: today
format: 
  html:
    page-layout: full
    html-math-method: katex
number-sections: true
toc: true
toc-location: left
toc-depth: 4
toc-title: ''
editor: source
bibliography: maxEff.bib
knitr:
  opts_chunk: 
    collapse: true
    comment: "#" 
vignette: >
  %\VignetteIndexEntry{intro}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

# Introduction

This vignette provides examples of using `R` packages

-   **`groupedHyperframe`**, @groupedHyperframe, [CRAN](https://cran.r-project.org/package=groupedHyperframe), [Github](https://github.com/tingtingzhan/groupedHyperframe), [RPubs](https://rpubs.com/tingtingzhan/groupedHyperframe)
-   **`maxEff`**, @maxEff, [CRAN](https://cran.r-project.org/package=maxEff), [Github](https://github.com/tingtingzhan/maxEff), [RPubs](https://rpubs.com/tingtingzhan/maxEff)

to select one from many `numeric` predictors for a regression model, to ensure that the additional predictor has the maximum effect size.

R terminology might be different from that of mathematics and statistics. Please refer to Appendix @sec-terms for explanation and reference of the terms and abbreviations used in this vignette.

Package **`maxEff`** `Imports` packages

-   `r '\U1f5dd'` **`caret`** [@caret, v`r packageVersion('caret')`], for data partition
-   `r '\U1f5dd'` **`groupedHyperframe`** (dev v`r packageVersion('groupedHyperframe')`), key dependency, for `S3` method dispatch `t.vectorlist()`
-   **`parallel`** shipped with `r R.version$version.string`, for parallel computing
-   `r '\U1f5dd'` **`rpart`** [@rpart, v`r packageVersion('rpart')`], key dependency, for recursive partitioning
-   `r '\U1f5dd'` **`spatstat.geom`** [@spatstat15, dev v`r packageVersion('spatstat.geom')`], key dependency, for `hyperframe` data structure

Package **`maxEff`** `Suggests` packages

-   `r '\U1f5dd'` **`survival`** [@survival, v`r packageVersion('survival')`], key suggest, <!--for function `survival:::as.data.frame.Surv()`--> to help `hyperframe` understand `Surv` object

Package **`groupedHyperframe`** dependencies are outlined in its separate vignette ([CRAN](https://cran.r-project.org/package=groupedHyperframe/vignettes/groupedHyperframe.html), [RPubs](https://rpubs.com/tingtingzhan/groupedHyperframe)).

## Prerequisite

Packages **`groupedHyperframe`** and **`maxEff`** require R version 4.5.0 (released 2025-04-11) or higher ([macOS](https://cran.r-project.org/bin/macosx/), [Windows](https://cran.r-project.org/bin/windows/base/)). An Integrated Development Environment (IDE), e.g., [RStudio](https://posit.co/download/rstudio-desktop/) [@RStudio] or [Positron](https://positron.posit.co/download.html), is not required, but highly recommended. This vignette is created under `r R.version$version.string` using packages **`knitr`** [@knitr, v`r packageVersion('knitr')`], **`quarto`** [@quarto, v`r packageVersion('quarto')` with [Quarto](https://quarto.org/docs/get-started/) v`r quarto::quarto_version()`] and **`rmarkdown`** [@rmarkdown, v`r packageVersion('rmarkdown')`].

```{r}
#| code-fold: true
#| code-summary: "Environment on author's computer"
Sys.info()[c('sysname', 'release', 'machine')]
R.version
```

Experimental (and maybe unstable) features are released *extremely frequently* to [Github](https://github.com/tingtingzhan/maxEff). [Active developers should use the Github version; suggestions and bug reports are welcome!]{style="background-color: #FFFF00"} Stable releases to [CRAN](https://CRAN.R-project.org/package=maxEff) are typically updated every 2 to 3 months, or when the authors have an upcoming manuscript in the peer-reviewing process.

```{r}
#| eval: false
remotes::install_github('tingtingzhan/groupedHyperframe')
remotes::install_github('tingtingzhan/maxEff')
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "Developers, do NOT use the CRAN version!"
utils::install.packages('groupedHyperframe') # Developers, do NOT use!!
utils::install.packages('maxEff') # Developers, do NOT use!!
```

## Getting Started

Examples in this vignette require that the `search` path has

```{r setup}
library(maxEff)
library(groupedHyperframe)
library(survival)
```

As of package **`spatstat.explore`** [@spatstat15, v`r packageVersion('spatstat.explore')`] and **`pROC`** [@pROC, v`r packageVersion('pROC')`], we have a function name clash between `spatstat.explore::plot.roc()` and `pROC::plot.roc()` when loading both packages **`groupedHyperframe`** (which `Imports` package **`spatstat.explore`**) and **`maxEff`** (which `Imports` package **`caret`** which `Imports` package **`pROC`**). This function name clash is potentially hazardous as the `S3` classes `spatstat.explore::roc` and `pROC::roc` are totally different.

```{r}
#| echo: false
#options(mc.cores = 1L) # for CRAN submission
```

## Acknowledgement

This work is supported by National Institutes of Health, U.S. Department of Health and Human Services grants

-   R01CA222847 ([I. Chervoneva](https://orcid.org/0000-0002-9104-4505), [T. Zhan](https://orcid.org/0000-0001-9971-4844), and [H. Rui](https://orcid.org/0000-0002-8778-261X))
-   R01CA253977 (H. Rui and I. Chervoneva).

# Examples

## Non-Spatial Example

[Point user to `groupedHyperframe` vignette, section *Publications*.]{style="background-color: yellow"}

[Copy language from `hyper.gam` vignette, section *Quantile Index*, subsection *Compute Aggregated Quantiles*.]{style="background-color: yellow"}

```{r}
Ki67q = groupedHyperframe::Ki67 |>
  within.data.frame(expr = {
    x = y = NULL # remove x- and y-coords for non-spatial application
  }) |>
  as.groupedHyperframe(group = ~ patientID/tissueID) |>
  aggregate_quantile(by = ~ patientID, probs = seq.int(from = .01, to = .99, by = .01))
```

```{r}
#| code-fold: true
#| code-summary: 'A `hyperframe` *`Ki67q`* with aggregated quantiles'
Ki67q |>
  head()
```

## Spatial Example

[Compose some English.]{style="background-color: yellow"}

[And share with `hyper.gam` vignette, section *Spatial Index*.]{style="background-color: yellow"}

```{r}
#| eval: false
Ki67s = groupedHyperframe::Ki67 |>
  grouped_ppp(formula = logKi67 ~ . | patientID/tissueID) |>
  Emark_(r = seq.int(from = 0, to = 100)) |>
  aggregate_fv(by = ~ patientID)
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: 'A `hyperframe` *`Ki67s`* with aggregated `Emark`'
Ki67s |>
  head()
```

# Data Partition

Partition into a training (80%) and test (20%) set.

```{r}
set.seed(32); id = sample.int(n = nrow(Ki67q), size = nrow(Ki67q)*.8) |> sort.int()
s0 = Ki67q[id, , drop = FALSE] # training set
s1 = Ki67q[-id, , drop = FALSE] # test set
```

```{r}
dim(s0)
```

```{r}
dim(s1)
```

# Starting Model

Let's consider a starting model of endpoint `PFS` with predictor `Tstage` on the training set *`s0`*. As of package **`spatstat.geom`** v`r packageVersion('spatstat.geom')`, the `S3` method dispatch `spatstat.geom::as.data.frame.hyperframe()` warns on hypercolumns that aren't able to be converted to a `data.frame`. Therefore, user should use `suppressWarnings()` or set `#| warning: false` in R markdown code–chunk.

```{r}
#| warning: false
m0 = coxph(PFS ~ Tstage, data = s0)
```

```{r}
#| code-fold: true
#| code-summary: Starting `coxph` model *`m0`*
summary(m0)
```

# Adding `numeric` Predictor

```{r}
a0 = m0 |>
  add_numeric(x = ~ logKi67.quantile) |>
  sort_by(y = abs(effsize), decreasing = TRUE) |>
  head(n = 2L)
```

The pipeline above consists of three steps.

First, function `add_numeric()`

-   considers each "slice" of the `numeric`-hypercolumn *`logKi67.quantile`* as an additional `numeric` predictor. Users are encourage to read the package **`groupedHyperframe`** [vignette](https://rpubs.com/tingtingzhan/groupedHyperframe), Appendix Section *On `anylist`* for more details;
-   `update`s the starting model *`m0`* with each one of the additional `numeric` predictors, respectively;
-   returns an `'add_numeric'` object, which `inherits` from the class `'add_'`. This is a `listof` objects with internal class `'add_numeric_'` (Appendix @sec-add_numeric_).

Second, the `S3` method dispatch `sort_by.add_()` sorts the input by the `abs`olute values of the regression coefficients, i.e., effect size `effsize`, of the additional `numeric` predictors.

Lastly, the `S3` method dispatch `utils:::head.default()` chooses the top `n` element from the input.

The `S3` method dispatch `print.add_numeric()` displays the `call`s to the selected `numeric` predictors.

```{r}
a0
```

The `S3` method dispatch `predict.add_numeric()` applies the starting model structure in *`m0`*, as well as the additional `numeric` predictors selected by *`a0`*, on the test set *`s1`*. The author categorizes this functionality under the `S3` generic `stats::predict()`, instead of `stats::update()`, to emphasize that this "update" is on a `newdata`, even that the workhorse function is the `S3` method dispatch `stats:::update.default()`.

```{r}
a1 = a0 |> 
  predict(newdata = s1)
```

```{r}
#| code-fold: true
#| code-summary: 'Predicted models *`a1`*' 
a1
```


# Adding `logical` Predictor

## Naive Practice {#sec-add_dummy}

```{r}
#| label: add_dummy
b0 = m0 |>
  add_dummy(x = ~ logKi67.quantile) |>
  subset(subset = p1 > .05 & p1 < .95) |> 
  sort_by(y = abs(effsize), decreasing = TRUE) |>
  head(n = 2L)
```

The pipeline above consists of four steps.

First, function `add_dummy()`

-   dichotomizes (Appendix @sec-node1) each "slice" of the `numeric`-hypercolumn *`logKi67.quantile`* into a `logical` variable;
-   removes the `duplicated` `logical` variables;
-   `update`s the starting model *`m0`* with each one of the additional `logical` predictors, respectively;
-   returns an `'add_dummy'` object, which `inherits` from the class `'add_'`. This is a `listof` objects with internal class `'add_dummy_'` (Appendix @sec-add_dummy_).

Second, the `S3` method dispatch `subset.add_dummy()` subsets the input by the balance of the partition of the additional `logical` predictor.

Third, the `S3` method dispatch `sort_by.add_()` sorts the input by the `abs`olute value of regression coefficients, i.e., effect size `effsize`, of the additional `logical` predictor.

Lastly, the `S3` method dispatch `utils:::head.default()` chooses the top `n` element from the input.

The `S3` method dispatch `print.add_dummy()` displays the `call`s to the selected `logical` predictors.

```{r}
b0
```

The `S3` method generic `predict.add_dummy()` applies the starting model structure in *`m0`*, as well as the additional `logical` predictors selected by *`b0`*, on the test set *`s1`*.

```{r}
b1 = b0 |> 
  predict(newdata = s1)
```

```{r}
#| code-fold: true
#| code-summary: 'Predicted models *`b1`*' 
b1
```


## via Repeated Partitions {#sec-add_dummy_partition}

```{r}
#| label: add_dummy_partition
set.seed(83); c0 = m0 |> 
  add_dummy_partition(~ logKi67.quantile, times = 20L, p = .8) |>
  subset(subset = p1 > .15 & p1 < .85) |>
  sort_by(y = abs(effsize), decreasing = TRUE) |>
  head(n = 2L)
```

The pipeline above consists of four steps.

First, function `add_dummy_partition()` creates a dichotomizing rule for each additional `numeric` predictor in the following steps.

1.  Generates twenty (`20L`) partitions of the training set *`s0`* using functions `caret::createDataPartition()` or `statusPartition()` (Appendix @sec-statusPartition) at `.8` vs. `.2=(1-.8)` ratio.
2.  For the $i$-th partition $(i=1,\cdots,20)$ of the training set *`s0`*,
    -   creates a dichotomizing rule of the `numeric` predictor in the [$i$-th training-subset of *`s0`*]{style="background-color: yellow"} using function `node1()` (Appendix @sec-node1);
    -   applies such dichotomizing rule to the `numeric` predictor in the [$i$-th test-subset of *`s0`*]{style="background-color: yellow"};
    -   `update`s the starting model *`m0`* with the [$i$-th test-subset of *`s0`*]{style="background-color: yellow"}, as well as the `logical` predictor from the previous step;
    -   records the estimated regression coefficients, i.e., effect size `effsize`, of the `logical` predictor.
3.  Selects the dichotomizing rule based on the partition with the `median` effect size of the `logical` predictor in [their own, specific test-subset of *`s0`*]{style="background-color: yellow"}.
4.  Returns an `'add_dummy'` object.

Second, the `S3` method dispatch `subset.add_dummy()` subsets the input by the balance of the partition of the additional `logical` predictor in [their own, specific test-subset of *`s0`*]{style="background-color: yellow"}.

Third, the `S3` method dispatch `sort_by.add_()` sorts the input by the `abs`olute value of regression coefficients, i.e., effect size `effsize`, of the additional `logical` predictor in [their own, specific test-subset of *`s0`*]{style="background-color: yellow"}.

Lastly, the `S3` method dispatch `utils:::head.default()` chooses the top `n` element from the input.

Similar to @sec-add_dummy, the `S3` method dispatch `print.add_dummy()` displays the `call`s to the selected `logical` predictors.

```{r}
c0
```

Similar to @sec-add_dummy, the `S3` method generic `predict.add_dummy()` applies the starting model structure in *`m0`*, as well as the additional `logical` predictors selected by *`c0`*, on the test set *`s1`*.

```{r}
c1 = c0 |> 
  predict(newdata = s1)
```

```{r}
#| code-fold: true
#| code-summary: 'Predicted models *`c1`*' 
c1
```


# Appendix

Technical details, as well as the minor and/or experimental features, are covered in the Appendix, in order not to interrupt the main narrative of this vignette.

All R code-chunks are folded in the Appendix, for ease of navigation. They are categorized as

-   **Data**, to create an R object for further operations.
-   **Review**, to demonstrate functions shipped with vanilla `r R.version.string`, or from other packages.
-   **Example**, to demonstrate functions from package **`maxEff`**.
-   **Advanced**, discussions for R experts.
-   **Figure**, to create a `ggplot`.
-   **Workaround**, to provide alternative solutions to a problem.


## `node1()` {#sec-node1}

Function `node1()` dichotomizes a single `numeric` `vector` based on the first node of a recursive partitioning and regression tree `rpart.object` from package **`rpart`** [@rpart]. In this section, we illustrate

-   the use of function `node1()`, and
-   the `S3` method dispatches `predict.node1()` and `labels.node1()`

using data examples from package **`rpart`**. To keep the user's `search` path simple and clean, we intentionally call the objects and functions in package **`rpart`** and **`survival`** [@survival] with explicit namespace, instead of using `library()` or `require()`.

Data set *`stagec`* from package **`rpart`** contains 146 subjects with [Stage C prostate cancer](https://www.cancer.org/cancer/types/prostate-cancer/detection-diagnosis-staging/staging.html).  We use the first 140 subjects as the training set, and the last 6 subjects as the test set.

```{r}
#| code-fold: true
#| code-summary: '**Data**: training set *`stagec0`* and test set *`stagec1`*'
data(stagec, package = 'rpart')
stagec0 = stagec[1:140,] # training set
stagec1 = stagec[-(1:140),] # test set
```

### `numeric` Predictor

Function `rpart::rpart()` creates a recursive partitioning model of the `numeric` variable *`age`* with the endpoint of progression-free survival in the training set *`stagec0`*, with

-   parameter `cp = .Machine$double.eps`, to ensure at least one node/split of the partitioning tree.
-   parameter `maxdepth = 2L`, to reduce the computation cost as we need only the first node.

```{r}
#| label: rpart_numeric
#| code-fold: true
#| code-summary: '**Review**: `rpart::rpart()`, `numeric` predictor'
rp0a = rpart::rpart(
  formula = survival::Surv(pgtime, pgstat) ~ age, 
  data = stagec0, 
  cp = .Machine$double.eps,
  maxdepth = 2L
)
rp0a
```

Function `node1()` creates a **dichotomizing rule** $\mathcal{D}$ of the `numeric` variable *`age`* based on the first node in the tree *`rp0a`*. Function `node1()` returns an object of class `'node1'`, which is also a [closure](https://en.wikipedia.org/wiki/Closure_(computer_programming)) that consists of a `function` and the `environment` in which it was created.

```{r}
#| label: node1_numeric
#| code-fold: true
#| code-summary: '**Example**: `node1()`, `numeric` predictor'
D0a = rp0a |>
  node1()
```

Dichotomizing rule *`D0a`* should be used as an R `function`.

```{r}
#| code-fold: true
#| code-summary: '**Example**: application of dichotomizing rule *`D0a`*'
set.seed(35); rnorm(n = 6L, mean = 53.5) |> 
  D0a()
```

The `S3` method dispatch `base::print.function()` displays the dichomizing rule *`D0a`* and its enclosure `environment`,

```{r}
#| code-fold: true
#| code-summary: '**Review**: `base::print.function()` on *`D0a`*'
D0a
```

The enclosure `environment` of the dichomizing rule *`D0a`* is intentionally cleaned up.

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: enclosure `environment` of *`D0a`*'
D0a |>
  environment() |>
  ls(envir = _)
D0a |>
  environment() |>
  ls(envir = _, all.names = TRUE)
```



The `name` of the `numeric` variable, e.g., *`age`*, is stored as the `formals` argument of the parameter *`newx`*. This is an advanced R programming trick. The `eval`uation of the dichotomizing rule discovers the variable *`age`* in

-   the global environment `.GlobalEnv`
-   the enclosure `environment` of the dichotomizing rule, if its `parent.env`ironment is a `namespace` or the `.GlobalEnv`

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: `eval`uate in `.GlobalEnv`'
age = stagec1$age
D0a()
rm(age)
```

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: `eval`uate in *`environment(D0a)`*, child of package `namespace`'
ev = environment(D0a)
parent.env(ev)
stopifnot(isNamespace(parent.env(ev)))
ls(envir = ev)
assign(x = 'age', value = stagec1$age, envir = ev)
D0a()
rm(age, envir = ev)
ls(envir = environment(D0a))
rm(ev)
```

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: `eval`uate in `new.env(parent = .GlobalEnv)`'
ev = new.env(parent = .GlobalEnv)
parent.env(ev)
assign(x = 'age', value = stagec1$age, envir = ev)
ls(envir = ev)
D0a. = D0a
environment(D0a.) = ev
D0a.()
tryCatch(expr = {
  as.function(D0a, envir = ev)()
}, error = identity)
tryCatch(expr = {
  eval(D0a(), envir = ev)
}, error = identity)
tryCatch(expr = {
  eval(D0a(), enclos = ev)
}, error = identity)  
rm(ev, D0a.)
```

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: `eval`uate in `list2env(., parent = .GlobalEnv)`'
ev = stagec1 |> 
  list2env(parent = .GlobalEnv) 
parent.env(ev)
D0a. = D0a
environment(D0a.) = ev
D0a.()
rm(ev, D0a.)
```

```{r}
#| code-fold: true
#| code-summary: '**Advanced**: do **not** `eval`uate in `as.environment()`, child of `emptyenv()` !'
ev = stagec1 |>
  as.environment()
parent.env(ev)
D0a. = D0a
environment(D0a.) = ev
tryCatch(expr = {
  D0a.()
}, error = identity)
rm(ev, D0a.)
```

The `S3` method dispatch `labels.node1()` returns a human-friendly `character` text to describe the dichotomizing rule $\mathcal{D}$.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `labels.node1()` on *`D0a`*'
D0a |> 
  labels()
```

The `S3` method dispatch `predict.node1()` dichotomizes the `numeric` variable *`age`* in the test set *`stagec1`*, using the dichotomizing rule *`D0a`* determined by the training set *`stagec0`*.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()` on *`D0a`*'
stagec1$age
D0a |> 
  predict(newdata = stagec1)
```

The (tentatively named) `S3` method dispatch `get_cutoff.node1()` returns the `numeric` cutoff value of the dichotomizing rule $\mathcal{D}$.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `get_cutoff.node1()` on *`D0a`*'
D0a |> 
  get_cutoff()
```

### `factor` Predictor

```{r}
#| label: rpart_factor
#| code-fold: true
#| code-summary: '**Review**: `rpart::rpart()`, `factor` predictor'
rp0b = rpart::rpart(
  formula = survival::Surv(pgtime, pgstat) ~ ploidy, 
  data = stagec0, 
  cp = .Machine$double.eps,
  maxdepth = 2L
)
rp0b
```

```{r}
#| label: node1_factor
#| code-fold: true
#| code-summary: '**Example**: `node1()`, `factor` predictor'
D0b = rp0b |>
  node1()
```

```{r}
#| code-fold: true
#| code-summary: '**Review**: `base::print.function()` on *`D0b`*'
D0b
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `labels.node1()` on *`D0b`*'
D0b |> 
  labels()
```


```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()` on *`D0b`*'
stagec1$ploidy
D0b |> 
  predict(newdata = stagec1)
```




## `statusPartition()` {#sec-statusPartition}

Function `statusPartition()`

1.  splits a `left`-censored `survival::Surv` object by its survival status, i.e., observed vs. `left`-censored;
2.  partitions the observed and `left`-censored subjects, respectively, into test/training sets.

We follow the terminology of the (very popular) function `caret::createDataPartition()`, that  

> We [**split**]{style="background-color: #FFFF00"} the data into multiple *strata*, and [**partition**]{style="background-color: #FFFF00"} each stratum into test/training sets.


Consider a toy example of 

```{r}
#| code-fold: true
#| code-summary: '**Data**: `left`-censored `Surv` object *`capacitor_failure`*'
capacitor_failure = survival::capacitor |> 
  with(expr = survival::Surv(time, status))
capacitor_failure
```



Function `statusPartition()` intends to avoid the situation that a Cox proportional hazards model `survival::coxph()` in one or more of the partitioned data set being degenerate due to the fact that all subjects in that partition being censored.


```{r}
#| label: statusPartition
#| code-fold: true
#| code-summary: '**Example**: `statusPartition()`'
set.seed(12); id = capacitor_failure |>
  statusPartition(times = 1L, p = .5)
capacitor_failure[id[[1L]], 2L] |> 
  table() # balanced by survival status
```


Function `statusPartition()` is an extension of the very popular function `caret::createDataPartition()`, which stratifies a `Surv` object by the `quantile`s of its survival time (as of package **`caret`** v`r packageVersion('caret')`).


```{r}
#| code-fold: true
#| code-summary: '**Review**: `caret::createDataPartition()`, *not* balanced by survival status'
set.seed(12); id0 = capacitor_failure |>
  caret::createDataPartition(times = 1L, p = .5)
capacitor_failure[id0[[1L]], 2L] |> 
  table()
```

## Class `'add_numeric_'` {#sec-add_numeric_}

The internal class `'add_numeric_'` `inherits` from the class `'call'`, with additional `attributes`

-   `attr(., 'effsize')`, a `numeric` scalar, regression coefficients, i.e., effect size `effsize`, of the additional `numeric` predictor
-   `attr(., 'model')`, the regression model with additional `numeric` predictor

The `S3` method dispatch `base::print.default()` displays each `'add_numeric_'` object.

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`a0`*, 1st element'
a0[[1L]]
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`a0`*, 2nd element'
a0[[2L]]
```

The `S3` method dispatch `spatstat.geom::with.hyperframe()` obtains the selected `numeric` predictors by passing the `call` to parameter `ee`.

```{r}
#| code-fold: true
#| code-summary: '**Example**: 1st selected `numeric` predictor'
s0 |>
  with(ee = a0[[1L]]) |> # ?spatstat.geom::with.hyperframe
  summary.default()
s1 |>
  with(ee = a0[[1L]]) |> # ?spatstat.geom::with.hyperframe
  summary.default()
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: 2nd selected `numeric` predictor'
s0 |>
  with(ee = a0[[2L]]) |> # ?spatstat.geom::with.hyperframe
  summary.default()
s1 |>
  with(ee = a0[[2L]]) |> # ?spatstat.geom::with.hyperframe
  summary.default()
```

The `S3` method dispatch `predict.add_numeric_()` is the workhorse of the `S3` method dispatch `predict.add_numeric()`.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_numeric_()`; predicted models *`a1`*, 1st element'
a11 = a0[[1L]] |> 
  predict(newdata = s1)
stopifnot(identical(a1[[1L]], a11))
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_numeric_()`; predicted models *`a1`*, 2nd element'
a12 = a0[[2L]] |> 
  predict(newdata = s1)
stopifnot(identical(a1[[2L]], a12))  
```

## Class `'add_dummy_'` {#sec-add_dummy_}

The internal class `'add_dummy_'` `inherits` from the class `'node1'` (Appendix @sec-node1), with additional `attributes`

-   `attr(., 'p1')`, a `numeric` scalar between 0 and 1, the `TRUE` probability of the additional `logical` predictor in the training set
-   `attr(., 'effsize')`, a `numeric` scalar, the regression coefficients, i.e., effect size `effsize`, of the additional `logical` predictor
-   `attr(., 'model')`, the regression model with additional `logical` predictor

The `S3` method dispatch `base::print.default()` displays each `'add_dummy_'` object.

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`b0`* in training set *`s0`*: 1st element'
b0[[1L]]
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`b0`* in training set *`s0`*: 2nd element'
b0[[2L]]
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`c0`* in test-subset of training set *`s0`*: 1st element'
c0[[1L]]
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: training models *`c0`* in test-subset of training set *`s0`*: 2nd element'
c0[[2L]]
```

The `S3` method dispatch `predict.node1()` evaluates a dichotomizing rule in a `hyperframe`. Note that user must call the `S3` method dispatch `predict.node1()` explicitly, otherwise the `S3` generic `stats::predict()` would dispatch to `predict.add_dummy_()`.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()`; 1st selected `logical` predictor'
b0[[1L]] |> 
  predict.node1(newdata = s0) |>
  table() |> 
  addmargins()  
b0[[1L]] |> 
  predict.node1(newdata = s1) |>
  table() |> 
  addmargins()
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()`; 2nd selected `logical` predictor'
b0[[2L]] |> 
  predict.node1(newdata = s0) |>
  table() |> 
  addmargins() 
b0[[2L]] |> 
  predict.node1(newdata = s1) |>
  table() |> 
  addmargins()  
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()`; 1st selected `logical` predictor via repeated partitions'
c0[[1L]] |>
  predict.node1(newdata = s0) |>
  table() |> 
  addmargins()
c0[[1L]] |>
  predict.node1(newdata = s1) |>
  table() |> 
  addmargins()
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.node1()`; 2nd selected `logical` predictor via repeated partitions'
c0[[2L]] |>
  predict.node1(newdata = s0) |>
  table() |> 
  addmargins()
c0[[2L]] |>
  predict.node1(newdata = s1) |>
  table() |> 
  addmargins()
```

The `S3` method dispatch `predict.add_dummy_()` is the workhorse of the `S3` method dispatch `predict.add_dummy()`.

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_dummy_()`; predicted models *`b1`*: 1st element'
b11 = b0[[1L]] |> 
  predict(newdata = s1)
stopifnot(identical(b1[[1L]], b11))
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_dummy_()`; predicted models *`b1`*: 2nd element'
b12 = b0[[2L]] |> 
  predict(newdata = s1)
stopifnot(identical(b1[[2L]], b12))  
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_dummy_()`; predicted models *`c1`*: 1st element'
c11 = c0[[1L]] |> 
  predict(newdata = s1)
stopifnot(identical(c1[[1L]], c11))
```

```{r}
#| code-fold: true
#| code-summary: '**Example**: `predict.add_dummy_()`; predicted models *`c1`*: 2nd element'
c12 = c0[[2L]] |> 
  predict(newdata = s1)
stopifnot(identical(c1[[2L]], c12))  
```

# What We Don't Do

## Use of "Optim"

In earlier publications, a junior author referred to the methodology outlined in @sec-add_dummy_partition using the term 'optim'.  This is a **wrong** practice of nomenclature, indicating a **wrong** understanding of R terminology.

In the world of R, an algorithm may use the term 'optim' if-and-only-if its core/workhorse function is either one of

-   [Brent–Dekker](https://en.wikipedia.org/wiki/Brent%27s_method) algorithm in one-dimensional optimization, via function `stats::optimize()` and/or its alias `stats::optimise()`.
-   [Nelder-Mead](https://en.wikipedia.org/wiki/Nelder–Mead_method), [quasi-Newton](https://en.wikipedia.org/wiki/Quasi-Newton_method), [conjugate-gradient](https://en.wikipedia.org/wiki/Conjugate_gradient_method) algorithms in higher-dimensional optimization, via function `stats::optim()`.

Otherwise, it is strongly advised **not** call an algorithm 'optim'.  

Therefore, we now name this package `maxEff`, meaning 'maximum effect size'.


# Terms & Abbreviations {#sec-terms}

@tbl-Rterm presents a comprehensive glossary of R terms and abbreviations used in this vignette.  

R terminology and nomenclature could be *drastically different* from that of mathematics and statistics.  Users are *strongly advised* to read closely from the links in @tbl-Rterm, which point to webpages on [search.r-project.org](https://search.r-project.org), [cran.r-project.org](https://cran.r-project.org), and [en.wikipedia.org](https://en.wikipedia.org).



| Term / Abbreviation | Description |
|:----|:----|
| CRAN, R | The Comprehensive R Archive Network, <https://cran.r-project.org> |
| `Depends`, `Imports`, `Suggests`, `Enhances` | [*Writing R Extensions*, Section 1.1.3 *Package Dependencies*](https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Package-Dependencies) |
| [`|>`](https://search.r-project.org/R/refmans/base/html/pipeOp.html) | Forward pipe operator introduced since R 4.1.0 |
| [`::`](https://search.r-project.org/R/refmans/base/html/ns-dblcolon.html) | Explicitly-[namespace](https://search.r-project.org/R/refmans/base/html/ns-reflect.html)d function or object |
| [`addmargins`](https://search.r-project.org/R/refmans/stats/html/addmargins.html) | Add margins to [`array`](https://search.r-project.org/R/refmans/base/html/array.html)s |
| [`as.environment`](https://search.r-project.org/R/refmans/base/html/as.environment.html) | Convert an object to an environment |
| [`abs`](https://search.r-project.org/R/refmans/base/html/MathFun.html) | Absolute value |
| [`call`](https://search.r-project.org/R/refmans/base/html/call.html) | Unevaluated expression |
| closure | <https://www.r-bloggers.com/2012/12/closures-in-r-a-useful-abstraction/>, <http://adv-r.had.co.nz/Functional-programming.html#closures> |
| [`coxph`](https://search.r-project.org/CRAN/refmans/survival/html/coxph.html) | Cox proportional hazards model |
| [`createDataPartition`](https://search.r-project.org/CRAN/refmans/caret/html/createDataPartition.html) | Test vs. training data set partition, from package **`caret`** [@caret] |
| [`duplicated`](https://search.r-project.org/R/refmans/base/html/duplicated.html) | Duplicate elements |
| [`emptyenv`](https://search.r-project.org/R/refmans/base/html/environment.html) | Empty environment |
| [`environment`](https://search.r-project.org/R/refmans/base/html/environment.html) | Environment |
| [`eval`](https://search.r-project.org/R/refmans/base/html/eval.html) | Evaluate an [`expression`](https://search.r-project.org/R/refmans/base/html/expression.html) |
| [`factor`](https://search.r-project.org/R/refmans/base/html/factor.html) | Factor, or categorical variable |
| [`formals`](https://search.r-project.org/R/refmans/base/html/formals.html) | Formal arguments |
| [`closure`, `function`](https://search.r-project.org/R/refmans/base/html/function.html) | R function |
| [`globalenv`, `.GlobalEnv`](https://search.r-project.org/R/refmans/base/html/environment.html) | Global environment |
| [`groupedHyperframe`](https://CRAN.R-project.org/package=groupedHyperframe) | Grouped hyper data frame, from package **`groupedHyperframe`** [@groupedHyperframe] |
| [`head`](https://search.r-project.org/R/refmans/utils/html/head.html) | First parts of an object |
| `hypercolumns`, [`hyperframe`](https://search.r-project.org/CRAN/refmans/spatstat.geom/html/hyperframe.html) | (Hyper columns of) hyper data frame, from package **`spatstat.geom`** [@spatstat05] |
| [`inherits`](https://search.r-project.org/R/refmans/base/html/class.html) | Class inheritance |
| [`labels`](https://search.r-project.org/R/refmans/base/html/labels.html) | Labels from object |
| [`levels`](https://search.r-project.org/R/refmans/base/html/levels.html) | Levels of a [`factor`](https://search.r-project.org/R/refmans/base/html/factor.html) |
| [`list2env`](https://search.r-project.org/R/refmans/stats/html/list2env.html) | Convert a [`list`](https://search.r-project.org/R/refmans/base/html/list.html) to [`environment`](https://search.r-project.org/R/refmans/base/html/environment.html) |
| [`listof`](https://search.r-project.org/R/refmans/stats/html/listof.html) | List of objects |
| `logistic` | Logistic regression model, `stats::glm(., family = binomial('logit'))` |
| [`matrix`](https://search.r-project.org/R/refmans/base/html/matrix.html) | Matrix |
| [`median`](https://search.r-project.org/R/refmans/stats/html/median.html) | Median value |
| [`optimize`, `optimise`](https://search.r-project.org/R/refmans/stats/html/optimize.html), [`optim`](https://search.r-project.org/R/refmans/stats/html/optim.html) | [Brent–Dekker](https://en.wikipedia.org/wiki/Brent%27s_method) in one-dimensional optimization; [Nelder-Mead](https://en.wikipedia.org/wiki/Nelder–Mead_method), [quasi-Newton](https://en.wikipedia.org/wiki/Quasi-Newton_method), [conjugate-gradient](https://en.wikipedia.org/wiki/Conjugate_gradient_method) in higher-dimensional optimizations |
| [`parent.env`](https://search.r-project.org/R/refmans/base/html/environment.html) | Parent environment |
| `PFS` | Progression/recurrence free survival, <https://en.wikipedia.org/wiki/Progression-free_survival> |
| [`predict`](https://search.r-project.org/R/refmans/stats/html/predict.html) | Model prediction |
| [`quantile`](https://search.r-project.org/R/refmans/stats/html/quantile.html) | Quantile |
| [`rpart`](https://search.r-project.org/CRAN/refmans/rpart/html/rpart.html), [`rpart.object`](https://search.r-project.org/CRAN/refmans/rpart/html/rpart.object.html), `node` | Recursive partitioning and regression trees |
| `S3`, `generic`, [`methods`](https://search.r-project.org/R/refmans/utils/html/methods.html) | `S3` object oriented system, [`UseMethod`](https://search.r-project.org/R/refmans/base/html/UseMethod.html); [`getS3method`](https://search.r-project.org/R/refmans/utils/html/getS3method.html); <https://adv-r.hadley.nz/s3.html> |
| `S4`, `generic`, `methods` | `S4` object oriented system, [`isS4`](https://search.r-project.org/R/refmans/base/html/isS4.html); [`setClass`](https://search.r-project.org/R/refmans/methods/html/setClass.html); [`setMethod`](https://search.r-project.org/R/refmans/methods/html/setMethod.html); [`getMethod`](https://search.r-project.org/R/refmans/methods/html/getMethod.html); <https://adv-r.hadley.nz/s4.html> |
| [`sort_by`](https://search.r-project.org/R/refmans/base/html/sort_by.html) | Sort an object by some criterion |
| [`str2lang`](https://search.r-project.org/R/refmans/base/html/str2lang.html) | To [`parse`](https://search.r-project.org/R/refmans/base/html/parse.html) R [`expression`](https://search.r-project.org/R/refmans/base/html/expression.html)s |
| [`subset`](https://search.r-project.org/R/refmans/base/html/subset.html) | Subsets of object by conditions |
| [`suppressWarnings`](https://search.r-project.org/R/refmans/base/html/warning.html) | Suppress warning messages |
| [`Surv`](https://search.r-project.org/CRAN/refmans/survival/html/Surv.html) | Survival, i.e., time-to-event, object, from package **`survival`** [@survival] |
| [`table`](https://search.r-project.org/R/refmans/base/html/table.html) | Cross tabulation |
| [`update`](https://search.r-project.org/R/refmans/stats/html/update.html) | Update and re-fit a model call |

: Terms & Abbreviations in R {#tbl-Rterm}




# References

::: {#refs}
:::
