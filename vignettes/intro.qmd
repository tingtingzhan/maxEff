---
title: "Additional Predictor with Maximum Effect Size"
author: Tingting Zhan
date: "`r format(Sys.time(), 'Last updated %d %B, %Y')`"
format: 
  html:
    page-layout: full
    html-math-method: katex
toc: true
toc-location: left
toc-depth: 4
toc-title: ''
editor: source
bibliography: maxEff.bib
knitr:
  opts_chunk: 
    collapse: true
    comment: "#>" 
vignette: >
  %\VignetteIndexEntry{intro}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

# Introduction

This vignette of package **`maxEff`** ([Github](https://github.com/tingtingzhan/maxEff), [RPubs](https://rpubs.com/tingtingzhan/maxEff)) documents three methods of selecting one from many `numeric` predictors for a regression model, to ensure that the additional predictor has the maximum effect size. 

R terminology might be different from that of mathematics and statistics. Please refer to Appendix @sec-terms for explanation and reference of the terms and abbreviations used in this vignette.

Package **`maxEff`** `Depends` packages

-   `r '\U1f5dd'` **`groupedHyperframe`** (dev v`r packageVersion('groupedHyperframe')`), key suggest, for the data structure of grouped hyper data frame

Package **`maxEff`** `Imports` packages

-   `r '\U1f5dd'` **`caret`** [@caret, v`r packageVersion('caret')`], for data partition
-   **`parallel`** shipped with `r R.version$version.string`, for parallel computing
-   `r '\U1f5dd'` **`rpart`** [@rpart, v`r packageVersion('rpart')`], key dependency, for recursive partitioning
-   `r '\U1f5dd'` **`spatstat.geom`** [@spatstat15, dev v`r packageVersion('spatstat.geom')`], key dependency, for additional support of `hyperframe`

Package **`maxEff`** `Suggests` packages

-   `r '\U1f5dd'` **`survival`** [@survival, v`r packageVersion('survival')`], key suggest, <!--for function `survival:::as.data.frame.Surv()`--> to help `hyperframe` understand `Surv` object

## Prerequisite

Package **`maxEff`** requires R version 4.5.0 (released 2025-04-11) or higher ([macOS](https://cran.r-project.org/bin/macosx/), [Windows](https://cran.r-project.org/bin/windows/base/)). An Integrated Development Environment (IDE), e.g., [RStudio](https://posit.co/download/rstudio-desktop/) or [Positron](https://positron.posit.co/download.html), is not required, but highly recommended. This vignette is created under `r R.version$version.string` using packages **`knitr`** [@knitr, v`r packageVersion('knitr')`], **`quarto`** [@quarto, v`r packageVersion('quarto')` with [Quarto](https://quarto.org/docs/get-started/) v`r quarto::quarto_version()`] and **`rmarkdown`** [@rmarkdown, v`r packageVersion('rmarkdown')`].

```{r}
#| code-fold: true
#| code-summary: "Environment on author's computer"
Sys.info()[c('sysname', 'release', 'machine')]
R.version
```

Package **`groupedHyperframe`** requires the development versions of the **`spatstat.*`** family of packages.

```{r}
#| eval: false
remotes::install_github('spatstat/spatstat', upgrade = 'always')
remotes::install_github('spatstat/spatstat.data', upgrade = 'always')
remotes::install_github('spatstat/spatstat.explore', upgrade = 'always')
remotes::install_github('spatstat/spatstat.geom', upgrade = 'always')
remotes::install_github('spatstat/spatstat.linnet', upgrade = 'always')
remotes::install_github('spatstat/spatstat.model', upgrade = 'always')
remotes::install_github('spatstat/spatstat.random', upgrade = 'always')
remotes::install_github('spatstat/spatstat.sparse', upgrade = 'always')
remotes::install_github('spatstat/spatstat.univar', upgrade = 'always')
remotes::install_github('spatstat/spatstat.utils', upgrade = 'always')
```

Experimental (and maybe unstable) features are released *extremely frequently* to [Github](https://github.com/tingtingzhan/maxEff). [Active developers should use the Github version; suggestions and bug reports are welcome!]{style="background-color: #FFFF00"} Stable releases to [CRAN](https://CRAN.R-project.org/package=maxEff) are typically updated every 2 to 3 months, or when the authors have an upcoming manuscript in the peer-reviewing process.

```{r}
#| eval: false
remotes::install_github('tingtingzhan/groupedHyperframe')
remotes::install_github('tingtingzhan/maxEff')
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "Developers, do NOT use the CRAN version!"
utils::install.packages('groupedHyperframe') # Developers, do NOT use!!
utils::install.packages('maxEff') # Developers, do NOT use!!
```




## Getting Started

Examples in this vignette require that the `search` path has

```{r setup}
library(maxEff)
library(survival)
```


As of package **`spatstat.explore`** [@spatstat15, v`r packageVersion('spatstat.explore')`] and **`pROC`** [@pROC, v`r packageVersion('pROC')`], we have a function name clash between `spatstat.explore::plot.roc()` and `pROC::plot.roc()` when loading both packages **`groupedHyperframe`** (which `Imports` package **`spatstat.explore`**) and **`maxEff`** (which `Imports` package **`caret`** which `Imports` package **`pROC`**).  This function name clash is potentially hazardous as the `S3` classes `spatstat.explore::roc` and `pROC::roc` are totally different.



```{r}
#| echo: false
#options(mc.cores = 1L) # for CRAN submission
```


## Acknowledgement

This work is supported by National Institutes of Health, U.S. Department of Health and Human Services grants

-   R01CA222847 ([I. Chervoneva](https://orcid.org/0000-0002-9104-4505), [T. Zhan](https://orcid.org/0000-0001-9971-4844), and [H. Rui](https://orcid.org/0000-0002-8778-261X))
-   R01CA253977 (H. Rui and I. Chervoneva).



# Data Preparation

<!--Data set `Ki67` in package **`groupedHyperframe`** is a `groupedHyperframe`.-->

```{r}
Ki67g = groupedHyperframe::Ki67 |>
  grouped_ppp(formula = logKi67 ~ PFS + Tstage + adj_rad + adj_chemo + histology + Her2 + HR + node + race + age | patientID/tissueID, data = _)
```

```{r}
s = Ki67g |>
  aggregate_quantile(by = ~ patientID, probs = seq.int(from = .01, to = .99, by = .01))
```

Candidate of additional predictors are stored in a `numeric`-`hypercolumn` *`logKi67.quantile`*. Users are encouraged to learn more about `groupedHyperframe` class and function `aggregate_quantile()` from package **`groupedHyperframe`** [vignette](https://rpubs.com/tingtingzhan/groupedHyperframe).

Partition into a training (80%) and test (20%) set.

```{r}
set.seed(32); id = sample.int(n = nrow(s), size = nrow(s)*.8) |> sort.int()
s0 = s[id, , drop = FALSE] # training set
s1 = s[-id, , drop = FALSE] # test set
```

Let's consider a starting model of endpoint `PFS` with predictor `Tstage` on the training set `s0`.

```{r}
suppressWarnings(m <- coxph(PFS ~ Tstage, data = s0))
summary(m)
```

# ðŸš§ Additional `numeric` Predictor

Function `add_numeric()` treats each additional predictor as a numeric variable, and `update`s the starting model with each additional predictor. Function `add_numeric()` returns an `add_numeric` object, which is a `listof` objects with an internal class `'add_numeric_'`.

The `S3` method dispatch `sort_by.add_()` sorts the `add_numeric` object by the `abs`olute value of the regression coefficient (i.e., effect size) of the additioanal numeric predictor.

The `S3` method dispatch `utils:::head.default()` chooses the top `n` element from the object returned from the previous step.

```{r}
set.seed(42); m1 = m |>
  add_numeric(x = ~ logKi67.quantile) |>
  sort_by(y = abs(effsize)) |>
  head(n = 2L)
m1
```

To find the selected additional numeric predictor,

```{r}
s0 |>
  with(ee = m1[[1L]]) |> # ?spatstat.geom::with.hyperframe
  head()
```

```{r}
s0 |>
  with(ee = m1[[2L]]) |> # ?spatstat.geom::with.hyperframe
  head()
```

The S3 method dispatch `predict.add_numeric()` uses model `m1` on the test set `s1`.

```{r}
m1[1L] |> predict(newdata = s1)
```

# ðŸš§ Additional `logical` Predictor

## ðŸš§ `add_dummy()`: Naive Practice

Function `add_dummy()` partitions each additional `numeric` predictor into a logical variable using function `node1()`, and `update`s the starting model by adding in each of the dichotomized `logical` predictor. Function `add_dummy()` returns an `'add_dummy'` object, which is a `listof` `node1` objects.

The `S3` method dispatch `subset.add_dummy()` subsets the the `'add_dummy'` object by the balance of partition of the additional predictor.

The `S3` method dispatch `sort_by.add_()` sorts the `'add_dummy'` object by the `abs`olute value of regression coefficient (i.e., effect size) of the additional logical predictor.

The `S3` method dispatch `utils:::head.default()` chooses the top `n` element from the object returned from the previous step.

```{r}
set.seed(14); m2 = m |>
  add_dummy(x = ~ logKi67.quantile) |>
  subset(subset = p1 > .05 & p1 < .95) |> 
  # need a [unique.add_dummy()] !!!!
  sort_by(y = abs(effsize)) |>
  head(n = 2L)
m2
```

To find the selected additional logical predictor,

```{r}
s |> 
  with(ee = m2[[1L]] |> attr(which = 'x')) |> # ?spatstat.geom::with.hyperframe
  m2[[1L]]() |>
  head(n = 20L)
```

```{r}
s |> 
  with(ee = m2[[2L]] |> attr(which = 'x')) |> # ?spatstat.geom::with.hyperframe
  m2[[2L]]() |>
  head(n = 20L)
```

The S3 method generic `predict.add_dummy()` uses model `m2` on the test set `s1`.

```{r}
m2[1L] |> predict(newdata = s1)
```

## ðŸš§ `add_dummy_partition()`: via Repeated Partitions

Function `add_dummy_partition()` partitions each additional `numeric` predictor into a `logical` variable in the following steps.

1.  Generate multiple, i.e., repeated, partitions.
2.  For each partition, create a dichotomizing rule (via function `node1()`) on the training set. Apply this dichotomizing rule on the test set and obtain the estimated regression coefficient (i.e., effect size) of the additional `logical` predictor.
3.  Among all partitions, select the one with median effect size of the additional `logical` predictor.

Function `add_dummy_partition()` also returns an `'add_dummy'` object.

```{r}
set.seed(83); m3 = m |> 
  add_dummy_partition(~ logKi67.quantile, times = 20L) |>
  subset(subset = p1 > .15 & p1 < .85) |>
  sort_by(y = abs(effsize), decreasing = TRUE) |>
  head(n = 2L)
m3
```

```{r}
m3[1L] |> predict(newdata = s1)
```

# Appendix

## `node1()` {#sec-node1}

Function `node1()` dichotomizes a single `numeric` `vector` based on the first node of a recursive partitioning and regression tree `rpart.object` from package **`rpart`** [@rpart]. In this section, we illustrate

-   the use of function `node1()`,
-   the `S3` class `'node1'`, and
-   the `S3` method dispatches to the class `'node1'`

using data examples from package **`rpart`**. To keep the user's `search` path simple and clean, we intentionally call functions in package **`rpart`** and **`survival`** [@survival] with explicit namespace, instead of using `library()` or `require()`.

Data example `rpart::stagec` contains 146 patients with stage C prostate cancer. We dichotomize the numeric variable *`age`* based on the recursive partitioning model with the endpoint of progression-free survival among the first 140 patients (training set). Note that the parameter `cp = .Machine$double.eps` of function `rpart::rpart()` ensures at least one node/split of the partitioning tree.

```{r}
data(stagec, package = 'rpart')
stagec0 = stagec[1:140,] # training set
stagec1 = stagec[-(1:140),] # test set
```

```{r}
fn1 = rpart::rpart(
  formula = survival::Surv(pgtime, pgstat) ~ age, 
  data = stagec0, 
  cp = .Machine$double.eps
) |>
  node1()
```

Function `node1()` creates a **dichotomizing rule** of the numeric variable *`age`*. Function `node1()` returns an object of class `'node1'`, which `inherits` from the class **`function`**, with additional `attributes`

-   `attr(, 'x')`, the `name` of the numeric variable, e.g., *`age`*, that is dichotomized

The `S3` method dispatch `print.node1()` displays the dichomizing rule as a `function` with minimal aesthetic touches,

```{r}
fn1
```

Dichotomizing rule *`fn1`* should be used as any R `function`.

```{r}
set.seed(35); rnorm(6, mean = 53.5) |> 
  fn1()
```

The `S3` method dispatch `predict.node1()` dichotomize the numeric variable *`age`* in the test set, using the dichotomizing rule *`fn1`* determined by the training set.

```{r}
data.frame(
  stagec1$age,
  Dichotomized = fn1 |> predict(newdata = stagec1),
  check.names = FALSE
)
```

Developers may obtain the `numeric` cutoff value of the dichotomizing rule *`fn1`*, or a brief text of to describe it, for further analysis.

```{r}
#| code-fold: true
#| code-summary: 'R code: subject to change!'
fn1 |> get_cutoff()
fn1 |> labels()
```

## `statusPartition()` {#sec-statusPartition}

Function `statusPartition()` partitions stratified a `survival::Surv` object based on its survival status, to avoid the situation that a Cox proportional hazards model `survival::coxph()` in one or more partitioned data set being degenerate due to the fact that all subjects in that partition being censored. Function `statusPartition()` is an extension of the very popular function `caret::createDataPartition()`, which stratifies a `Surv` object by the `quantile`s of its survival time (as of package **`caret`** v`r packageVersion('caret')`).

```{r}
y = survival::capacitor |> 
  with(expr = Surv(time, status))
```

```{r}
set.seed(15); id = y |>
  statusPartition(times = 1L, p = .5)
table(y[id[[1L]], 2L]) / table(y[,2L]) # balanced by survival status
```

```{r}
set.seed(15); id0 = y |>
  caret::createDataPartition(times = 1L, p = .5)
table(y[id0[[1L]], 2L]) / table(y[,2L]) # *not* balanced by survival status
```

## Terms & Abbreviations {#sec-terms}

| Term / Abbreviation | Description |
|------------------------------------|------------------------------------|
| [`|>`](https://search.r-project.org/R/refmans/base/html/pipeOp.html) | Forward pipe operator introduced since R 4.1.0 |
| [`abs`](https://search.r-project.org/R/refmans/base/html/MathFun.html) | Absolute value |
| [`coxph`](https://search.r-project.org/CRAN/refmans/survival/html/coxph.html) | Cox proportional hazards model |
| CRAN, R | The Comprehensive R Archive Network, <https://cran.r-project.org> |
| [`createDataPartition`](https://search.r-project.org/CRAN/refmans/caret/html/createDataPartition.html) | Test vs. training data set partition, from package **`caret`** [@caret] |
| [`factor`](https://search.r-project.org/R/refmans/base/html/factor.html) | Factor, or categorical variable |
| [`function`](https://search.r-project.org/R/refmans/base/html/function.html) | R function |
| [`groupedHyperframe`](https://CRAN.R-project.org/package=groupedHyperframe) | Grouped hyper data frame |
| [`head`](https://search.r-project.org/R/refmans/utils/html/head.html) | First parts of an object |
| `hypercolumns`, [`hyperframe`](https://search.r-project.org/CRAN/refmans/spatstat.geom/html/hyperframe.html) | (Hyper columns of) hyper data frame, from package **`spatstat.geom`** [@spatstat05] |
| [`labels`](https://search.r-project.org/R/refmans/base/html/labels.html) | Labels from object, `maxEff::labels.node1` |
| [`levels`](https://search.r-project.org/R/refmans/base/html/levels.html) | Levels of a [`factor`](https://search.r-project.org/R/refmans/base/html/factor.html) |
| [`listof`](https://search.r-project.org/R/refmans/stats/html/listof.html) | List of objects |
| `logistic` | Logistic regression model, `stats::glm(., family = binomial(\'logit\'))` |
| [`matrix`](https://search.r-project.org/R/refmans/base/html/matrix.html) | Matrix |
| `PFS` | Progression/recurrence free survival, <https://en.wikipedia.org/wiki/Progression-free_survival> |
| [`predict`](https://search.r-project.org/R/refmans/stats/html/predict.html) | Model prediction, `maxEff::predict.add_numeric`; `maxEff::predict.add_dummy` |
| [`quantile`](https://search.r-project.org/R/refmans/stats/html/quantile.html) | Quantile |
| [`rpart`](https://search.r-project.org/CRAN/refmans/rpart/html/rpart.html), [`rpart.object`](https://search.r-project.org/CRAN/refmans/rpart/html/rpart.object.html), `node` | Recursive partitioning and regression trees |
| `S3`, `generic`, [`methods`](https://search.r-project.org/R/refmans/utils/html/methods.html) | `S3` object oriented system, [`UseMethod`](https://search.r-project.org/R/refmans/base/html/UseMethod.html); [`getS3method`](https://search.r-project.org/R/refmans/utils/html/getS3method.html); <https://adv-r.hadley.nz/s3.html> |
| `S4`, `generic`, `methods` | `S4` object oriented system, [`isS4`](https://search.r-project.org/R/refmans/base/html/isS4.html); [`setClass`](https://search.r-project.org/R/refmans/methods/html/setClass.html); [`setMethod`](https://search.r-project.org/R/refmans/methods/html/setMethod.html); [`getMethod`](https://search.r-project.org/R/refmans/methods/html/getMethod.html); <https://adv-r.hadley.nz/s4.html> |
| [`sort_by`](https://search.r-project.org/R/refmans/base/html/sort_by.html) | Sort an object by some criterion, `maxEff::sort_by.add_` |
| [`subset`](https://search.r-project.org/R/refmans/base/html/subset.html) | Subsets of object by conditions, `maxEff::subset.add_dummy` |
| [`Surv`](https://search.r-project.org/CRAN/refmans/survival/html/Surv.html) | Survival, i.e., time-to-event, object, from package **`survival`** [@survival] |
| [`update`](https://search.r-project.org/R/refmans/stats/html/update.html) | Update and re-fit a model call |

# References

::: {#refs}
:::
