---
title: "Additional Predictor with Maximum Effect Size"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{intro}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

# Introduction

This vignette ...

## Note to Users

Examples in this vignette require that the `search` path has

```{r setup}
library(maxEff)
library(groupedHyperframe)
library(survival)
```

Users should remove parameter `mc.cores = 1L` from all examples and use the default option, which engages all CPU cores on the current host for macOS. The authors are forced to have `mc.cores = 1L` in this vignette in order to pass `CRAN`'s submission check.


## List of Terms and Abbreviations

```{r echo = FALSE, results = 'asis'}
c(
  '`abs`', 'Absolute value', '`base::abs`',
  '`function`', 'R function', '``base::`function` ``',
  '`groupedHyperframe`', 'Grouped hyper data frame', 'https://www.github.com/tingtingzhan/groupedHyperframe',
  '`head`', 'First parts of an object', 'Generic `utils::head`; Dispatch `utils:::head.default`',
  '`listof`', 'List of objects (of same class)', '`stats::listof`',
  '`matrix`', 'Matrix', '`base::matrix`',
  '`PFS`', 'Progression/recurrence free survival', 'https://en.wikipedia.org/wiki/Progression-free_survival',
  '`predict`', 'Model prediction', 'Generic `stats::predict`. Dispatches `maxEff::predict.add_num`; `maxEff::predict.add_dummy_rSplit`',
  '`rpart`', 'Recursive partitioning and regression trees', '`rpart::rpart`',
  '`S3`', '`R`\'s simplest object oriented system', 'https://adv-r.hadley.nz/s3.html',
  '`sort_by`', 'Sort an object by some criterion', 'Generic `base::sort_by`. Dispatch `maxEff::sort_by.add_`',
  '`subset`', 'Subsets of object by conditions', 'Generic `base::subset`. Dispatch `maxEff::subset.add_dummy`',
  '`update`', 'Update and re-fit a model call', 'Generic `stats::update`'
) |>
  matrix(nrow = 3L, dimnames = list(c('Term / Abbreviation', 'Description', 'Reference'), NULL)) |>
  t.default() |>
  as.data.frame.matrix() |> 
  kable()
```



# Dichotomize via First Node of Recursive Partitioning

Function `rpart1()` returns a dichotomizing rule, i.e., a **`function`**,
determined by the first node of a recursive partitioning and regression tree.

```{r}
data(cu.summary, package = 'rpart')
(foo = cu.summary |> with.default(expr = rpart1(y = Price, x = Mileage)))
```

The returned dichotomizing rule `foo` converts a `numeric` object to a `logical` object.

```{r}
set.seed(125); rnorm(6, mean = 24.5) |> foo()
```

Developers may obtain the `numeric` cutoff value of the dichotomizing rule `foo`, or a brief text of to describe the it, for downstream analysis.

```{r}
get_cutoff(foo)
labels(foo)
```

# Data Preparation

Data preparation

```{r}
s = Ki67 |>
  within.data.frame(expr = {
    Ki67 = log1p(Ki67)
    PFS = Surv(time = recfreesurv_mon, event = recurrence)
  }) |>
  grouped_ppp(formula = Ki67 ~ PFS + node + Tstage | patientID/tissueID, coords = FALSE) |>
  aggregate_quantile(by = ~ patientID, probs = seq.int(from = .01, to = .99, by = .01))
```

Users are encouraged to learn more about functions `grouped_ppp()` and `aggregate_quantile()` from vignette of package **`groupedHyperframe`**.

```{r eval = FALSE}
devtools::install_github('tingtingzhan/groupedHyperframe', build_vignettes = TRUE)
vignette('intro', package = 'groupedHyperframe')
```

Candidate of additional predictors are stored in a `matrix`-column.  Each additional predictor is a column of this `matrix`-column.

```{r}
names(s)
s$Ki67.quantile |> dim()
s$Ki67.quantile |> colnames() |> head()
```


Partition into a training (80%) and test (20%) set.

```{r}
set.seed(234); id = sort.int(sample.int(n = nrow(s), size = nrow(s)*.8))
s0 = s[id, , drop = FALSE] # training set
s1 = s[-id, , drop = FALSE] # test set
```

Let's consider a starting model of endpoint `PFS` with predictor `Tstage` on the training set `s0`.

```{r}
summary(m <- coxph(PFS ~ Tstage, data = s0))
```

# Additional `numeric` Predictors with Maximum Effect Size

Function `add_num()` treats each additional predictor as a `numeric` variable, and `update` the starting model with each additional predictor.  Function `add_num()` returns an `'add_num'` object, which is a `listof` objects with an internal class `'add_num_'`.

The `S3` generic `sort_by()` sorts the `'add_num'` object by the `abs`olute value of regression coefficient (i.e., effect size). 

The `S3` generic `head()` chooses the first `n` element from the `'add_num'` object returned from the previous step.

```{r}
set.seed(14837); m1 = m |>
  add_num(x = ~ Ki67.quantile, mc.cores = 1L) |>
  sort_by(y = abs(effsize)) |>
  head(n = 2L)
m1
```

The S3 generic `predict()` uses model `m1` on the test set `s1`.

```{r}
predict(m1, newdata = s1)
```


# Additional `logical` Predictors with Maximum Effect Size

## Naive Practice: `add_dummy()`

Function `add_dummy()` partitions each additional `numeric` predictor into a `logical` variable base on the first node of recursive partitioning (via function `rpart1()`) , and update the starting model with each `logical` additional predictor. Function `add_dummy()` returns an `'add_dummy'` object, which is a `listof` objects with class `'rpart1'`.

The `S3` generic `subset()` subsets the the `'add_dummy'` object by the balance of partition of the additional predictor. Example below shows that we prefer not to consider a dichotomized predictor which is more unbalanced than 15%/85%.

The `S3` generic `sort_by()` sorts the `'add_dummy'` object by the `abs`olute value of regression coefficient (i.e., effect size).

The `S3` generic `head()` chooses the first `n` element from the `'add_dummy'` object returned from the previous step.


```{r}
set.seed(14837); m2 = m |>
  add_dummy(x = ~ Ki67.quantile) |> 
  subset(subset = p1 > .15 & p1 < .85) |> 
  sort_by(y = abs(effsize)) |>
  head(n = 2L)
m2
```

The S3 generic `predict()` uses model `m2` on the test set `s1`.

```{r}
# predict(m2, newdata = s1) # author too lazy; not done yet
```


## `add_dummy_rSplit()`

Function `add_dummy_rSplit()`

```{r}
set.seed(14837); m3 = m |> 
  add_dummy_rSplit(~ Ki67.quantile, n = 20L) |>
  subset(subset = p1 > .15 & p1 < .85) |>
  sort_by(y = abs(effsize), decreasing = TRUE) |>
  head(n = 2L)
m3
```


```{r}
predict(m3, newdata = s1)
```
